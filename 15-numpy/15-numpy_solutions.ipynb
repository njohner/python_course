{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Exercises 15: numpy\n",
    "Let's get some work done with numpy arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 15.1: numpy array basics\n",
    "### Exercise 15.1.1\n",
    "* import numpy\n",
    "* Define an array `a1d` with values between -1 and 1 with a step of 0.1 (i.e. [-1, -0.9, ..., 0.9, 1])\n",
    "* print out the size (number of elements) of the array (it should be 21!)\n",
    "* Now define a 2-dimensional array `zeros_2d` with 4 rows and 3 columns of zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a1d = np.arange(-1, 1.01, 0.1)\n",
    "print(a1d.size)\n",
    "print(a1d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros_2d = np.zeros((4, 3))\n",
    "print(zeros_2d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 15.1.2\n",
    "Let's do some slicing\n",
    "* Using the `reshape` method I created `a2d` with 10 rows and 2 columns from the elements of `a1d` except the last one. Have a look at it.\n",
    "* Now print the first element of the second column\n",
    "* Print the second row\n",
    "* Print the second column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a2d = a1d[:-1].reshape(10,2)\n",
    "print(a2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a2d[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a2d[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a2d[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 15.1.3\n",
    "Numpy arrays are mutable objects. Still working on `a2d`\n",
    "* Change the second element of the second row to `np.nan`. Verify by printing the second row\n",
    "* Change the first row to `[0, 0]`. Again print out the first row to verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a2d[1, 1] = np.nan\n",
    "print(a2d[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a2d[0] = [0, 0]\n",
    "# or a2d[0] = 0\n",
    "print(a2d[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 15.1.4: masks\n",
    "Masks allow to work with only parts of a numpy array that fulfill a given condition.\n",
    "* Make an array containing all elements that are `np.nan` in `a1d`.\n",
    "* Now make an array with all elements that are not `np.nan` in `a1d` (you can use `np.logical_not` to invert a boolean array)\n",
    "* **Supplementary**: On `a2d` make an array with all rows that do not have a `np.nan` in the second column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a1d)\n",
    "print(np.isnan(a1d))\n",
    "print(a1d[np.isnan(a1d)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.logical_not(np.isnan(a1d)))\n",
    "print(a1d[np.logical_not(np.isnan(a1d))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a2d)\n",
    "# have a look at the mask we will use:\n",
    "print(np.logical_not(np.isnan(a2d[:, 1])))\n",
    "\n",
    "# Using that mask leaves us with all rows not having np.nan in the second column\n",
    "a2d[np.logical_not(np.isnan(a2d[:, 1]))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 15.2: statistics on numpy arrays\n",
    "### Exercise 15.2.1\n",
    "I generated an array `data_1d` containing 100 random numbers drawn from a normal distribution (with mean 2 and standard deviation 0.5) for you.\n",
    "* Calculate its average\n",
    "* Calculate its standard deviation\n",
    "* Now normalise the data into a new array `normalised` by substracting the average and dividing by the standard deviation. Print its average and standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1d = np.random.normal(2, 0.5, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"average(data) = {:.3}\".format(np.mean(data_1d)))\n",
    "print(\"std(data) = {:.3}\".format(np.std(data_1d)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalised = (data_1d - np.mean(data_1d)) / np.std(data_1d)\n",
    "print(\"average(normalised) = {:.2f}\".format(np.mean(normalised)))\n",
    "print(\"std(normalised) = {:.2f}\".format(np.std(normalised)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 15.2.2\n",
    "Lets look at some multidimensional data. We will load a toy dataset from the scikit-learn package: the diabetes dataset. This dataset looks at how various parameters influence the disease progression. We load the data into a variable `diabetes`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "try:\n",
    "    diabetes = load_diabetes(scaled=False)\n",
    "except:\n",
    "    diabetes = load_diabetes()\n",
    "    diabetes.data[:,1] = np.where(diabetes.data[:,1] > 0, 2, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 15.2.2 a\n",
    "A description of the data can be found in `diabetes.DESCR`, print it and have a look at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(diabetes.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 15.2.2 b\n",
    "The data itself can be accessed with `diabetes.data`, which is a numpy array of the values for the 10 features measured. Print out its shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"diabetes data shape:\", diabetes.data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 15.2.2 c\n",
    "The target value, here a measure of the disease progression is in `diabetes.target`. The name of the features can be found in `diabetes.feature_names`. Calculate the correlation between disease progression (`diabetes.target`) and age (first column of the data) and print it. \n",
    "\n",
    "*HINT: `np.corrcoef` gives back a correlation matrix, the coefficient you want is the first element of the second column.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = np.corrcoef(diabetes.data[:, 0], diabetes.target)\n",
    "print(corr)\n",
    "print(\"correlation between age and disease progression: {:.2f}\".format(corr[0, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 15.2.2 d\n",
    "Now calculate the correlation coefficient for every feature in the data set and print it. Which feature is most highly correlated to the disease progression?\n",
    "\n",
    "Instead of simply printing that information you could also save it to a list to make it usable afterwards.\n",
    "\n",
    "*Hint: The easiest is to use a for loop to iterate over all columns of the data with an index*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations = []\n",
    "for i, feature in enumerate(diabetes.feature_names):\n",
    "    correlations.append(np.corrcoef(diabetes.data[:, i], diabetes.target)[0, 1])\n",
    "    print(\"Corr for {}: {:.2f}\".format(feature, correlations[-1]))\n",
    "    \n",
    "# Now we find the feature with highest correlation\n",
    "# argmax gives the position of the maximal value\n",
    "max_index = np.argmax(np.abs(correlations))\n",
    "print(\"\\nmost highly correlated feature is:\")\n",
    "print(diabetes.feature_names[max_index], \": \", correlations[max_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 15.2.2 e\n",
    "Among the features, there is one that is categorical: `sex`. Correlation is obviously a bad measure for a categorical variable. Instead, calculate the average disease progression for men and for women (`sex` equal to 1 or to 2). \n",
    "\n",
    "*HINT: Use a mask*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "female = diabetes.data[:, 1] == 2\n",
    "male = np.logical_not(female)\n",
    "mean_female = np.mean(diabetes.target[female])\n",
    "mean_male = np.mean(diabetes.target[male])\n",
    "print(\"mean disease progression, men: {:.4}\".format(mean_male))\n",
    "print(\"mean disease progression, women: {:.4}\".format(mean_female))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supplementary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 15.2.2 f\n",
    "To know whether this difference is significant or not, we would need a statistical test. But the basic idea is that if the difference in average is large compared to the standard deviation, this might be significant. Calculate the standard deviations of the disease progression for these two categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_male = np.std(diabetes.target[male])\n",
    "std_female = np.std(diabetes.target[female])\n",
    "print(\"std men: {:.3}\".format(std_male))\n",
    "print(\"std women: {:.3}\".format(std_female))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 15.2.2 g\n",
    "Now in order to estimate significance calculate `(0.5*n_samples)**0.5 * (mu1-mu2) / (sd1**2+sd2**2)**0.5`, where `mu1` and `mu2` are the two averages, `sd1` and `sd2` the standard deviations and `n_samples` the number of measurements. This is an estimation of a student t-test in the case where sample size and variance is the same in both groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(mean_female - mean_male)/((std_male**2 + std_female**2)**0.5)*(0.5*diabetes.data.shape[0])**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 15.2.2 h\n",
    "Let's directly do a t-test. The function is found in `scipy.stats.ttest_ind`. Import it and use it to test the significance of the categorical variable on the disease progression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "stats.ttest_ind(diabetes.target[male],diabetes.target[female])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 15.3 Line Fit\n",
    "We redo Ex. 11.5 but using numpy, which makes it much easier.\n",
    "In this exercise we will write a very simple function to find the best fit line to a set of points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex. 15.3.1\n",
    "We start by writing a function to compute the mean squared error between two numpy arrays, i.e. the sum of the residues: $MSE = \\frac{1}{n}\\sum_{i=1}^{n}(x_i-y_i)^2$\n",
    "- Define the function `mean_squared_error` taking two numpy arrays `vec1` and `vec2` as parameters\n",
    "- Test it on a few examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_squared_error(vec1, vec2):\n",
    "    return np.average((vec1 - vec2) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1, 2, 3])\n",
    "y = np.array([2, 2, 2])\n",
    "print(\"MSE({}, {}) = {}\".format(x, y, mean_squared_error(x, y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex. 15.3.2\n",
    "#### Ex. 15.3.2a\n",
    "We will now write a very basic optimization method using simple brute force to calculate a best fit line. The `brute_force_line_fit` method should have two parameters `x` and `y`. It should search the best fit parameters `a` and `b` so that the MSE between the prediction $a*x + b$ and $y$ is as small as possible. The function can simply use as search space all floats between -10 and 10 with a step of 0.1 both for $a$ and for $b$. It should return the optimal values for $a$ and $b$ as well as the corresponding MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def brute_force_line_fit(x, y):\n",
    "    \"\"\"Fits a linear model (a * x) + b and return the best fit parameters\n",
    "    as well as the MSE.\n",
    "    \"\"\"\n",
    "    best_error = None\n",
    "    best_a = None\n",
    "    best_b = None\n",
    "    for a in np.arange(-10, 10, step=0.1):\n",
    "        for b in np.arange(-10, 10, step=0.1):\n",
    "            prediction = a * x + b\n",
    "            error = mean_squared_error(y, prediction)\n",
    "            if best_error is None or error < best_error:\n",
    "                best_error = error\n",
    "                best_a = a\n",
    "                best_b = b\n",
    "    return {'a': best_a, 'b': best_b, 'mse': best_error}        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ex. 15.3.2b\n",
    "Test the `brute_force_line_fit` function on the follwing $x$ and $y$ data that I have prepared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_a = 2.12\n",
    "real_b = 3.23\n",
    "x = np.arange(0, 10, 0.2)\n",
    "y = real_a * x + real_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = brute_force_line_fit(x, y)\n",
    "print(\"Real values were: a = {}; b = {}\".format(real_a, real_b))\n",
    "print(\"Estimates are: a = {}; b = {}\".format(res[\"a\"], res[\"b\"]))\n",
    "print(\"MSE = {}\".format(res['mse']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cas_pml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
