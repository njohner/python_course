{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises 19: scikit-learn\n",
    "Let's have a look at the basics of scikit-learn.\n",
    "\n",
    "Below I've made the basic imports, loaded the data and made a copy of both the features and the target. I've defined `n_learn` as the number of data points we will use for learning and split the data into a training set `train_data` and testing set `test_data` (and `train_target` and `test_target`) using `sklearn.model_selection.train_test_split`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "try:\n",
    "    diabetes = load_diabetes(scaled=False)\n",
    "except:\n",
    "    diabetes = load_diabetes()\n",
    "    diabetes.data[:,1] = np.where(diabetes.data[:,1] > 0, 2, 1)\n",
    "\n",
    "# We make a copy of the diabetes data to work on\n",
    "data = np.copy(diabetes.data)\n",
    "target = np.copy(diabetes.target)\n",
    "\n",
    "# now we split the data into a training and a test set\n",
    "n_learn = 280\n",
    "train_data, test_data, train_target, test_target = \\\n",
    "train_test_split(data, target, train_size = n_learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessors and estimators from scikit-learn function exactly as the ones we have defined in Exercises 18 on classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 19.1\n",
    "In this exercise we will use `scikit-learn` to train a linear model on the `diabetes` data and then test the quality of the model we have just fitted. \n",
    "\n",
    "*Note that this is the exact same model we have fitted in Supplementary Ex. 18.4 with the same quality of fit and the estimator also functions very similarly.*\n",
    "\n",
    "### Exercise 19.1.1\n",
    "* Create an instance of a linear estimator (use `sklearn.linear_model.LinearRegression`)\n",
    "* Use it to fit the data (We only use `train_data` and `train_target` for training.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "lin_reg = linear_model.LinearRegression()\n",
    "\n",
    "\n",
    "# we fit the regressor to the training data\n",
    "lin_reg.fit(train_data, train_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 19.1.2\n",
    "Now let's look at the predictions from our trained estimator. For that we will make a plot of the predicted disease progression vs the real disease progression (target values).\n",
    "\n",
    "* Use the trained estimator to predict the disease progression for the training data (call the prediction `train_predicted_target`).\n",
    "* Use the trained estimator to predict the disease progression for the test data (call the prediction `test_predicted_target`).\n",
    "* Make a plot of the predictions vs the real disease progression (so one series of points is `train_predicted_target` vs `train_target` and the second series is `test_predicted_target` vs `test_target`)\n",
    "\n",
    "Can you tell whether the model is overfitted?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use the regressor to predict the disease progression for the training data\n",
    "train_predicted_target = lin_reg.predict(train_data)\n",
    "# and for the test data\n",
    "test_predicted_target = lin_reg.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "# plot the actual disease progression versus the predicted progression for the test set\n",
    "plt.plot(test_target, test_predicted_target, \"bx\", label=\"test\")\n",
    "\n",
    "# plot the actual disease progression versus the predicted progression for the training set\n",
    "plt.plot(train_target, train_predicted_target, \"rx\", label=\"training\")\n",
    "\n",
    "# Add a line representing the perfect prediction\n",
    "plt.plot(plt.xlim(), plt.xlim(), \"--\")\n",
    "\n",
    "# Add labels and such\n",
    "plt.xlabel(\"Target\")\n",
    "plt.ylabel(\"Prediction\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is not overfitted as the quality of the fit is similar for the training and the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 19.1.3\n",
    "Let's now numerically evaluate the quality of our model. We do this by calculating the average error made by the prediction from our estimator compared to the real disease progerssion (on the test data). We do this in two different ways:\n",
    "* Calculate the mean squared error using the metric provided by scikit-learn, namely the `mean_squared_error` from `sklearn.metrics` module (it takes two arguments, the target values and its prediction: `mean_squared_error(target, prediction)`)\n",
    "* Estimator objects also have a `score` method, which gives a default evaluation for a given class of methods. For regression this returns the $R^2$ coefficient of determination. Calculate it and print it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = mean_squared_error(test_target, test_predicted_target)\n",
    "print(\"error for the linear model\", error)\n",
    "r2 = lin_reg.score(test_data, test_target)\n",
    "print(\"r2 for the linear model\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 19.2\n",
    "Now we redo the same thing as in the previous exercise but with a support-vector machine. Here we are doing a regression, so use `sklearn.svm.SVR` and repeat the previous exercise, except that we start by normalizing the data. For this we use a preprocessor from scikit-learn, `sklearn.preprocessing.StandardScaler`, which removes the average and divides by the standard deviation (this class functions exactly as the scaler we have defined in Ex 18.2).\n",
    "\n",
    "### Exercise 19.2.1\n",
    "* Import the necessary classes (`StandardScaler` and `SVR`)\n",
    "* Instantiate a `StandardScaler`, then fit it to the training data\n",
    "* Normalize the data (both training and test) using the normalizer\n",
    "* Then, as above, create an estimator, fit it to the normalized data, calculate the mean squared error and the $R^2$ coefficient (`score` method) and print the results\n",
    "* Make a plot of disase progression vs predicted progression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "norm = StandardScaler()\n",
    "\n",
    "# we fit the normaliser to the training data\n",
    "norm.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the normaliser to transform the training and test data\n",
    "train_data_normed = norm.transform(train_data)\n",
    "test_data_normed = norm.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now fit a support vector machine regressor to our normalised data\n",
    "svr = SVR()\n",
    "svr.fit(train_data_normed, train_target)\n",
    "\n",
    "# We calculate the error and print it\n",
    "error = mean_squared_error(test_target, svr.predict(test_data_normed))\n",
    "print(\"error for the svm\", error)\n",
    "\n",
    "# We score the estimator\n",
    "r2 = svr.score(test_data_normed, test_target)\n",
    "print(\"r2 for the svm\",r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "# plot the actual disease progression versus the predicted progression for the test set\n",
    "plt.plot(test_target, svr.predict(test_data_normed), \"bx\", label=\"test\")\n",
    "\n",
    "# plot the actual disease progression versus the predicted progression for the training set\n",
    "plt.plot(train_target, svr.predict(train_data_normed), \"rx\", label=\"training\")\n",
    "\n",
    "# Add a line representing the perfect prediction\n",
    "plt.plot(plt.xlim(),plt.xlim(), \"--\")\n",
    "\n",
    "# Add labels and such\n",
    "plt.xlabel(\"Target\")\n",
    "plt.ylabel(\"Prediction\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 19.2.2\n",
    "Results obtained with the SVR above are pretty bad. Let's tweak the estimator a bit. Set the `kernel=\"sigmoid\"` and the `C=10`, then test the estimator as above, i.e.:\n",
    "- Initialize the estimator with `SVR(kernel=\"sigmoid\", C=10)`, then fit the estimator \n",
    "- Fit the model to the data\n",
    "- Predict the target for the training and test data\n",
    "- Plot the prediction against the actual target\n",
    "- Calculate the mean squared error and ùëÖ2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now fit a support vector machine regressor to our normalised data\n",
    "svr = SVR(kernel=\"sigmoid\", C=10)\n",
    "svr.fit(train_data_normed, train_target)\n",
    "\n",
    "# We calculate the error and print it\n",
    "error = mean_squared_error(test_target, svr.predict(test_data_normed))\n",
    "print(\"error for the svm\", error)\n",
    "\n",
    "# We score the estimator\n",
    "r2 = svr.score(test_data_normed, test_target)\n",
    "print(\"r2 for the svm\",r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "# plot the actual disease progression versus the predicted progression for the test set\n",
    "plt.plot(test_target, svr.predict(test_data_normed), \"bx\", label=\"test\")\n",
    "\n",
    "# plot the actual disease progression versus the predicted progression for the training set\n",
    "plt.plot(train_target, svr.predict(train_data_normed), \"rx\", label=\"training\")\n",
    "\n",
    "# Add a line representing the perfect prediction\n",
    "plt.plot(plt.xlim(),plt.xlim(), \"--\")\n",
    "\n",
    "# Add labels and such\n",
    "plt.xlabel(\"Target\")\n",
    "plt.ylabel(\"Prediction\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 19.3\n",
    "Finally we try with a regression tree. \n",
    "### Exercise 19.3.1\n",
    "Repeat Exercise 19.2.1 but using `sklearn.tree.DecisionTreeRegressor`. Again use the normalized data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "tree_reg = DecisionTreeRegressor()\n",
    "tree_reg.fit(train_data_normed, train_target)\n",
    "error = mean_squared_error(test_target, tree_reg.predict(test_data_normed))\n",
    "print(\"error for the tree\", error)\n",
    "r2 = tree_reg.score(test_data_normed, test_target)\n",
    "print(\"r2 for the tree\",r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(test_target, tree_reg.predict(test_data_normed), \"bx\", label=\"test\")\n",
    "plt.plot(train_target, tree_reg.predict(train_data_normed), \"rx\", label=\"training\")\n",
    "plt.plot(plt.xlim(),plt.xlim(), \"--\")\n",
    "plt.xlabel(\"Target\")\n",
    "plt.ylabel(\"Prediction\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supplementary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 19.3.2\n",
    "Our estimetor from exercise 19.3.1 is clearly overfitted. This is because by default the depth of the tree is unlimited and tree is expanded until all leaves are pure. With the `max_depth` parameter, the depth of the tree can be controlled. One way to determine the optimal depth of the tree is to look at how the prediction error evolves with the depth of the tree on the training and testing data set and determine the depth for which prediction on the testing data set is best.\n",
    "- Calculate the Mean Squared Error (for the training and testing data) for `DecisionTreeRegressor`s fitted to depths ranging from 1 to 20.\n",
    "- Plot the resulting errors as a function of the tree depth\n",
    "- Determine the optimal `max_depth` to use\n",
    "- Make the plot of target vs prediction for the `DecisionTreeRegressor` fitted with the optimal `max_depth`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_error = []\n",
    "test_error = []\n",
    "for i in range(1, 21):\n",
    "    tree_reg = DecisionTreeRegressor(max_depth=i)\n",
    "    tree_reg.fit(train_data_normed, train_target)\n",
    "    test_error.append(mean_squared_error(test_target, tree_reg.predict(test_data_normed)))\n",
    "    train_error.append(mean_squared_error(train_target, tree_reg.predict(train_data_normed)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(range(1, 21), test_error, \"rx\", label=\"test error\")\n",
    "plt.plot(range(1, 21), train_error, \"go\",label=\"train error\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_reg = DecisionTreeRegressor(max_depth=3)\n",
    "tree_reg.fit(train_data_normed, train_target)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(test_target, tree_reg.predict(test_data_normed), \"bx\", label=\"test\")\n",
    "plt.plot(train_target, tree_reg.predict(train_data_normed), \"rx\", label=\"training\")\n",
    "plt.plot(plt.xlim(),plt.xlim(), \"--\")\n",
    "plt.xlabel(\"Target\")\n",
    "plt.ylabel(\"Prediction\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "error = mean_squared_error(test_target, tree_reg.predict(test_data_normed))\n",
    "print(\"error for the tree\", error)\n",
    "r2 = tree_reg.score(test_data_normed, test_target)\n",
    "print(\"r2 for the tree\",r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 19.4: feature engineering\n",
    "In this exercise we will add more features to our dataset. We will do this by generating all the terms of degree 2 between our features, using the `PolynomialFeatures` class.\n",
    "- Use the `PolynomialFeatures` class to create a new feature set containing also all terms of degree 2\n",
    "- Then repeat the steps from the other exercises, using a linear model (`LinearRegression`), i.e.:\n",
    "  - Fit the model to the new data\n",
    "  - Predict the target for the training and test data\n",
    "  - Plot the prediction against the actual target\n",
    "  - Calculate the mean squared error and $R^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly = PolynomialFeatures(2)\n",
    "augmented_train_data = poly.fit_transform(train_data)\n",
    "augmented_test_data = poly.fit_transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a linear model to the augmented data\n",
    "lin_reg = linear_model.LinearRegression()\n",
    "lin_reg.fit(augmented_train_data, train_target)\n",
    "\n",
    "# Use the model to predict the disease progression for the training and test data\n",
    "train_predicted_target = lin_reg.predict(augmented_train_data)\n",
    "test_predicted_target = lin_reg.predict(augmented_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the prediction against the target values\n",
    "plt.figure()\n",
    "plt.plot(test_target, test_predicted_target, \"bx\", label=\"test\")\n",
    "plt.plot(train_target, train_predicted_target, \"rx\", label=\"training\")\n",
    "plt.plot(plt.xlim(),plt.xlim(), \"--\")\n",
    "\n",
    "plt.xlabel(\"Target\")\n",
    "plt.ylabel(\"Prediction\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = mean_squared_error(test_target, test_predicted_target)\n",
    "print(\"error for the linear model\", error)\n",
    "r2 = lin_reg.score(augmented_test_data, test_target)\n",
    "print(\"r2 for the linear model\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
