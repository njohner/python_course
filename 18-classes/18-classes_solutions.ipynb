{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises 18: Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get familiar with writing classes. This will allow you to organize your code much better, make it more reusable and diminish code dupplication by using inheritance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex. 18.1\n",
    "We start with the class from the course and add new functionnality to it. I've modified the class from the course a bit, by adding documentation. Have a look at how these docstrings appear when using the `help` function on the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Calculator():\n",
    "    \"\"\"This class tracks a current value and allows to make successive\n",
    "    operations on that value.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.current_state = 0\n",
    "\n",
    "    def print_state(self):\n",
    "        \"\"\"Prints the current_state.\n",
    "        \"\"\"\n",
    "        print(self.current_state)\n",
    "\n",
    "    def add(self, x):\n",
    "        \"\"\"Adds x to the current_state\n",
    "        \"\"\"\n",
    "        self.current_state += x\n",
    "        self.print_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(Calculator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex. 18.1.1\n",
    "Add a method `substract`, to substract a given value from the `current_state` of the calculator, then try it out.\n",
    "You will need to either copy the whole definition of the classe above and add the new `substract` method, or create a class that inherits from the above `Calculator` class but additionally defines the `substract` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Calculator():\n",
    "    \"\"\"This class tracks a current value and allows to make successive\n",
    "    operations on that value.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.current_state = 0\n",
    "\n",
    "    def print_state(self):\n",
    "        \"\"\"Prints the current_state.\n",
    "        \"\"\"\n",
    "        print(self.current_state)\n",
    "\n",
    "    def add(self, x):\n",
    "        \"\"\"Adds x to the current_state\n",
    "        \"\"\"\n",
    "        self.current_state += x\n",
    "        self.print_state()\n",
    "    \n",
    "    def substract(self, x):\n",
    "        \"\"\"Substracts x from the current_state\n",
    "        \"\"\"\n",
    "        self.add(-x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc = Calculator()\n",
    "calc.add(4)\n",
    "calc.substract(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex. 18.1.2\n",
    "Now we add a `reset` method, which sets the `current_state` back to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResettableCalculator(Calculator):\n",
    "    \"\"\"This class tracks a current value and allows to make successive\n",
    "    operations on that value.\n",
    "    \"\"\"\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Reset the current_state to 0\"\"\"\n",
    "        self.current_state = 0\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc = ResettableCalculator()\n",
    "calc.add(10)\n",
    "calc.reset()\n",
    "calc.print_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex. 18.1.3\n",
    "Finally try to modify the `__init__` method so that it has a second parameter `initial_value`, which is used to set the initial value of `current_state`. Give it a default value of `0`, so that if I don't specify `initial_value`, `current_state` will be set to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Calculator():\n",
    "    \"\"\"This class tracks a current value and allows to make successive\n",
    "    operations on that value.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, initial_value=0):\n",
    "        self.current_state = initial_value\n",
    "        \n",
    "    def print_state(self):\n",
    "        \"\"\"Prints the current_state.\n",
    "        \"\"\"\n",
    "        print(self.current_state)\n",
    "\n",
    "    def add(self, x):\n",
    "        \"\"\"Adds x to the current_state\n",
    "        \"\"\"\n",
    "        self.current_state += x\n",
    "        self.print_state()\n",
    "    \n",
    "    def substract(self, x):\n",
    "        \"\"\"Substracts x from the current_state\n",
    "        \"\"\"\n",
    "        self.add(-x)\n",
    "        \n",
    "    def reset(self):\n",
    "        \"\"\"Reset the current_state to 0\"\"\"\n",
    "        self.current_state = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc = Calculator(8)\n",
    "calc.print_state()\n",
    "\n",
    "calc_default = Calculator()\n",
    "calc_default.print_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex 18.2: Scaler\n",
    "Let's now turn to data analysis and training models.\n",
    "\n",
    "Below I've made the basic imports, loaded the diabetes data and made a copy of both the features and the target.\n",
    "We also split the data into a learning set and a prediction set. I've defined `n_learn` as the number of data points we will use for learning and split the data into `train_data` and `test_data` (and `train_target` and `test_target`) using `sklearn.model_selection.train_test_split`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import optimize\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "try:\n",
    "    diabetes = load_diabetes(scaled=False)\n",
    "except:\n",
    "    diabetes = load_diabetes()\n",
    "    diabetes.data[:,1] = np.where(diabetes.data[:,1] > 0, 2, 1)\n",
    "\n",
    "features = np.copy(diabetes.data)\n",
    "target = np.copy(diabetes.target)\n",
    "\n",
    "n_learn = 280\n",
    "train_data, test_data, train_target, test_target = \\\n",
    "train_test_split(features, target, train_size = n_learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex 18.2.1:\n",
    "We now write a class that we will use to normalise the data before using it to train a model. The class (`StandardScaler`) should have an `__init__` method, a `fit` method and a `transform` method. For simplicity we limit ourselves to one-dimensional data.\n",
    "- Normalization of `data` is simply done by substracting the average and dividing by the standard deviation: `data = (data - np.average(data)) / np.std(data)` except that the average and the standard deviation will be stored on the scaler in the `fit` method and used in the `transform` method.\n",
    "- I prepared the backbone of the class for you. Fill in wherever necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StandardScaler1D:\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Initializes the mean_ and scale_ values to None. Those will then be set when \n",
    "        fitting the scaler to some data\"\"\"\n",
    "        self.mean_ = None\n",
    "        self.scale_ = None\n",
    "    \n",
    "    def fit(self, data):\n",
    "        \"\"\"Extract the average and standard deviation from the data and save it in the\n",
    "        corresponding attributes (mean_ and scale_)\n",
    "        \"\"\"\n",
    "        self.mean_ = np.average(data)\n",
    "        self.scale_ = np.std(data)\n",
    "    \n",
    "    def transform(self, data):\n",
    "        \"\"\"Use the stored mean_ and scale_ attributes to normalise the data and return it.\n",
    "        \"\"\"\n",
    "        if self.mean_ is None or self.scale_ is None:\n",
    "            print(\"You must fit the scaler before you can use it to normalise data\")\n",
    "            return None\n",
    "        return (data - self.mean_) / self.scale_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex. 18.2.2\n",
    "We now test our `StandardScaler1D` on the first column of `train_data` and `test_data`, which I have prepared in `train_data0` and `test_data0`\n",
    "- Use the scaler to learn on `train_data0` how to normalise the data\n",
    "- Apply that normalisation to `train_data0`, call the normalised data `train_data0_normed`. \n",
    "- Apply that normalisation to `test_data0`, call the normalised data `test_data0_normed`. This is closer to a real situation, as training the normaliser is part of training a model, and as such this cannot be done on the `test_data0`, but only on the `train_data0`.\n",
    "- Check that the normalised data have averages close to 0 and standard deviations close to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data0 = train_data[:,0]\n",
    "test_data0 = test_data[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler1D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After initialisation and before fitting to the data, mean_ and scale_ are None\n",
    "print(\"scaler mean is None before fit:\", scaler.mean_ is None)\n",
    "\n",
    "# We train the scaler on the training data:\n",
    "scaler.fit(train_data0)\n",
    "\n",
    "# By fitting the scaler was trained which set mean_ and scale_\n",
    "print(scaler.mean_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the normalisation to the train_data, will perfectly normalise it, as the\n",
    "# normalizer was trained on that data\n",
    "train_data0_normed = scaler.transform(train_data0)\n",
    "print(\"train average: {}, train std: {}\".format(np.average(train_data0_normed), np.std(train_data0_normed)))\n",
    "\n",
    "# If our test data was a large enough and representative enough set of data\n",
    "# applying the scaler to the test set should lead to good normalisation, i.e. \n",
    "# mean and std close to 0 and 1 respectively.\n",
    "test_data0_normed = scaler.transform(test_data0)\n",
    "print(\"test average: {}, test std: {}\".format(np.average(test_data0_normed), np.std(test_data0_normed)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex. 18.2.3 (Supplementary)\n",
    "Redo the exercise above but writing a scaler that works for multidimensional data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StandardScaler:\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Initializes the mean_ and scale_ values to None. Those will then be set when \n",
    "        fitting the scaler to some data\"\"\"\n",
    "        self.mean_ = None\n",
    "        self.scale_ = None\n",
    "    \n",
    "    def fit(self, data):\n",
    "        \"\"\"Extract the average and standard deviation from the data and save it in the\n",
    "        corresponding attributes (mean_ and scale_)\n",
    "        \"\"\"\n",
    "        self.mean_ = np.average(data, axis=0)\n",
    "        self.scale_ = np.std(data, axis=0)\n",
    "    \n",
    "    def transform(self, data):\n",
    "        \"\"\"Use the stored mean_ and scale_ attributes to normalise the data and return it.\n",
    "        \"\"\"\n",
    "        if self.mean_ is None or self.scale_ is None:\n",
    "            print(\"You must fit the scaler before you can use it to normalise data\")\n",
    "            return None\n",
    "        return (data - self.mean_) / self.scale_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After initialisation and before fitting to the data, mean_ and scale_ are None\n",
    "print(scaler.mean_ is None)\n",
    "\n",
    "# We train the scaler on the training data:\n",
    "scaler.fit(train_data)\n",
    "\n",
    "# By fitting the scaler was trained which set mean_ and scale_\n",
    "print(scaler.mean_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the normalisation to the train_data, will perfectly normalise it, as the\n",
    "# normalizer was trained on that data\n",
    "train_data_normed = scaler.transform(train_data)\n",
    "print(\"train average: {}, train std: {}\".format(np.average(train_data_normed, axis=0), np.std(train_data_normed, axis=0)))\n",
    "\n",
    "# If our test data was a large enough and representative enough set of data\n",
    "# applying the scaler to the test set should lead to good normalisation, i.e. \n",
    "# mean and std close to 0 and 1 respectively.\n",
    "test_data_normed = scaler.transform(test_data)\n",
    "print(\"test average: {}, test std: {}\".format(np.average(test_data_normed, axis=0), np.std(test_data_normed, axis=0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex. 18.3: Estimator\n",
    "In this exercise we will make a simple estimator ourselves. Similarly to Exercise 17.1.2, we will do a linear fit of the target data (disease progression) vs the BMI. As a reminder this was done like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line(x, a, b): \n",
    "    return a*x + b\n",
    "\n",
    "bmi_index = diabetes.feature_names.index(\"bmi\")\n",
    "train_feature = train_data[:, bmi_index]\n",
    "fit_result = optimize.curve_fit(line, train_feature, train_target)\n",
    "print(fit_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will instead create a class that will allow us to do the linear fit and then use the fitted result to predict the housing price from the data. I wrote the class for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleLinearEstimator:\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"self.a and self.b will be used to store the slope and intercept\n",
    "        of our linear model. They get initialized to None here and\n",
    "        will be set when fitting the estimator to some data.\n",
    "        \"\"\"\n",
    "        self.a = None\n",
    "        self.b = None\n",
    "\n",
    "    def model(self, x, a, b): \n",
    "        return a*x + b\n",
    "    \n",
    "    def fit(self, features, target):\n",
    "        \"\"\"This method fits the model, i.e. it searches for the optimal weights\n",
    "        a and b, so that the output of the model when applied on features will match\n",
    "        target as closely as possible.\n",
    "        \"\"\"\n",
    "        fit_result = optimize.curve_fit(self.model, features, target, method=\"dogbox\")\n",
    "        # curve_fit returns a tuple containing the optimal weights as first\n",
    "        # element. We store them on our instance in self.a and self.b:\n",
    "        self.a = fit_result[0][0]\n",
    "        self.b = fit_result[0][1]\n",
    "        \n",
    "    def predict(self, features):\n",
    "        \"\"\"This method applies the optimized model on features and returns\n",
    "        the predicted value for the target.\n",
    "        \"\"\"\n",
    "        if self.a is None or self.b is None:\n",
    "            print(\"You must fit the estimator before you can use it to make predictions\")\n",
    "            return None\n",
    "        return self.model(features, self.a, self.b)\n",
    "    \n",
    "    def score(self, features, target):\n",
    "        \"\"\"Evaluate the quality of the estimator. This is done by using the fitted model\n",
    "        to predict the target values from the data and compare them with target. The metric\n",
    "        used for this comparison is the mean squared error.\n",
    "        \"\"\"\n",
    "        if self.a is None or self.b is None:\n",
    "            print(\"You must fit the estimator before you can score it\")\n",
    "            return None\n",
    "        predicted = self.predict(features)\n",
    "        return np.average((predicted - target)**2.0)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex. 18.3.1\n",
    "- Use the above defined class to make a linear fit of `train_target` vs `train_feature` defined above (disease progression vs bmi).\n",
    "- use the estimator to predict the disease progression from the bmi (on `test_feature = test_data[:, 2]`)\n",
    "- plot the predicted disease progression against the real disease progression (`test_target`) to check the quality of your prediction\n",
    "- score the estimator (print the mean squared error made when using the estimator to predict `test_target` from `test_feature`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We instantiate the estimator.\n",
    "estimator = SimpleLinearEstimator()\n",
    "# After instantiation the parameters of the linear regression are undefined\n",
    "print(\"a, b before fit\", estimator.a, estimator.b)\n",
    "\n",
    "# We then train the estimator on the training data\n",
    "estimator.fit(train_feature, train_target)\n",
    "# This will fit the linear model to the data, and the estimator will store the\n",
    "# parameters of the fit.\n",
    "print(\"a, b after fit\", estimator.a, estimator.b)\n",
    "\n",
    "# We now use the estimator to predict the price of houses from the number of rooms\n",
    "# for the test set:\n",
    "test_feature = test_data[:, bmi_index]\n",
    "predicted_target = estimator.predict(test_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We plot the real housing price of the test set against our prediction\n",
    "plt.figure()\n",
    "plt.plot(test_target, predicted_target, \"x\")\n",
    "\n",
    "# We add the diagonal here, which is equivalent to a perfect prediction\n",
    "plt.plot(plt.xlim(), plt.xlim(), \"--\")\n",
    "plt.xlabel(\"Disease Progression\")\n",
    "plt.ylabel(\"Predicted Progression\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally we score our estimator.\n",
    "print(\"Mean squared error on prediction:\", estimator.score(test_feature, test_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supplementary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex. 18.4\n",
    "Write an estimator `LinearEstimator` (inspired from `SimpleLinearEstimator`) to fit the disease progression but using all 10 features instead of a single feature. We can actually write it so that it will fit a linear model to any number of features. Then test the `LinearEstimator` on the diabetes dataset, similarly to what was done in 18.2.1\n",
    "\n",
    "*Hints*:\n",
    "- *`model` should take `x` as parameter as above and then an arbitrary number of weights (use `*weights` as described in the supplementary slides and exercises of part 11 of the course on Functions)*\n",
    "- *`optimize.curve_fit` needs to know how many parameters `model` needs, as it will call that function during the fit. It cannot guess it here as `model` takes an arbitrary number of parameters, hence you will need to pass it an additional argument `p0=np.ones(n_params)`, where `n_params` is the number of parameters `model` takes (not counting `x`).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearEstimator:\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"self.weights will be used to store the weights\n",
    "        of our linear model. It gets initialized to None here and\n",
    "        will be set when fitting the estimator to some data.\n",
    "        \"\"\"\n",
    "        self.weights = None\n",
    "\n",
    "    def model(self, x, *weights):\n",
    "        return np.sum(x * weights[:-1], axis=1) + weights[-1]\n",
    "\n",
    "    def get_n_params(self, features):\n",
    "        return features.shape[1] + 1\n",
    "    \n",
    "    def fit(self, features, target):\n",
    "        \"\"\"This method fits the model, i.e. it searches for the optimal weights\n",
    "        a and b, so that the output of the model when applied on data will match\n",
    "        target as closely as possible.\n",
    "        \"\"\"\n",
    "        self.n_params = self.get_n_params(features)\n",
    "        res = optimize.curve_fit(self.model, features, target, p0=np.ones(self.n_params), method=\"dogbox\")\n",
    "        \n",
    "        # curve_fit returns a tuple containing the optimal weights as first\n",
    "        # element. We store them on our instance in self.weights:\n",
    "        self.weights = res[0]\n",
    "        \n",
    "    def predict(self, features):\n",
    "        \"\"\"This method applies the optimized model on features and returns\n",
    "        the predicted value for the target.\n",
    "        \"\"\"\n",
    "        if self.weights is None:\n",
    "            print(\"You must fit the estimator before you can use it to make predictions\")\n",
    "            return None\n",
    "        return self.model(features, *self.weights)\n",
    "\n",
    "    def score(self, features, target):\n",
    "        if self.weights is None:\n",
    "            print(\"You must fit the estimator before you can score it\")\n",
    "            return None\n",
    "        predicted = self.predict(features)\n",
    "        return np.average((predicted - target)**2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = LinearEstimator()\n",
    "estimator.fit(train_data_normed, train_target)\n",
    "predicted_target = estimator.predict(test_data_normed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(test_target, predicted_target, \"x\")\n",
    "plt.plot(plt.xlim(), plt.xlim(), \"--\")\n",
    "plt.xlabel(\"Disease Progression\")\n",
    "plt.ylabel(\"Predicted Progresion\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean squared error on prediction:\", estimator.score(test_data_normed, test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
